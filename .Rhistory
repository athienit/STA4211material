3  2  3  3  3
3  2  3  3  4
6  3  3  2  5
4  3  3  2  6
"
apples=read.table(textConnection(Input),header=T)
#apples=read.table("https://raw.githubusercontent.com/athienit/STA4211material/main/KutnerData/Chapter%2028%20Data%20Sets/CH28TA11.txt",header=F)
#colnames(apples)=c("Sales","Pattern","Order","Display","Store")
apples$Pattern=as.factor(apples$Pattern)
apples$Order=as.factor(apples$Order)
apples$Display=as.factor(apples$Display)
apples$Store=as.factor(apples$Store)
ddply(apples, ~Display, summarize, means=mean(Sales))
apples.LSD=aov(Sales~Display+Pattern+Order+Store,data=apples)
summary(apples.LSD)
apples=read.table("https://raw.githubusercontent.com/athienit/STA4211material/main/KutnerData/Chapter%2028%20Data%20Sets/CH28TA11.txt",header=F)
colnames(apples)=c("Sales","Pattern","Order","Display","Store")
apples$Pattern=as.factor(apples$Pattern)
apples$Order=as.factor(apples$Order)
apples$Display=as.factor(apples$Display)
apples$Store=as.factor(apples$Store)
ddply(apples, ~Display, summarize, means=mean(Sales))
apples.LSD=aov(Sales~Display+Pattern+Order+Store:Pattern,data=apples)
summary(apples.LSD)
Input="
Sales Pattern Order Display Store
9  1  1  2  1
4  1  1  2  2
12  2  1  1  3
13  2  1  1  4
7  3  1  3  5
5  3  1  3  6
12  1  2  3  1
12  1  2  3  2
14  2  2  2  3
14  2  2  2  4
18  3  2  1  5
20  3  2  1  6
15  1  3  1  1
9  1  3  1  2
3  2  3  3  3
3  2  3  3  4
6  3  3  2  5
4  3  3  2  6
"
apples=read.table(textConnection(Input),header=T)
apples$Pattern=as.factor(apples$Pattern)
apples$Order=as.factor(apples$Order)
apples$Display=as.factor(apples$Display)
apples$Store=as.factor(apples$Store)
Input="
Sales Pattern Order Display StoreW1 StoreW2
9  1  1  2  1  1
4  1  1  2  2  2
12  2  1  1  3  1
13  2  1  1  4  2
7  3  1  3  5  1
5  3  1  3  6  2
12  1  2  3  1  1
12  1  2  3  2  2
14  2  2  2  3  1
14  2  2  2  4  2
18  3  2  1  5  1
20  3  2  1  6  2
15  1  3  1  1  1
9  1  3  1  2  2
3  2  3  3  3  1
3  2  3  3  4  2
6  3  3  2  5  1
4  3  3  2  6  2
"
apples=read.table(textConnection(Input),header=T)
apples$Pattern=as.factor(apples$Pattern)
apples$Order=as.factor(apples$Order)
apples$Display=as.factor(apples$Display)
apples$StoreW1=as.factor(apples$StoreW1)
apples$StoreW2=as.factor(apples$StoreW2)
ddply(apples, ~Display, summarize, means=mean(Sales))
apples.LSDW1=aov(Sales~Display+Pattern+Order+StoreW1,data=apples)
apples.LSDW2=aov(Sales~Display+Pattern+Order+StoreW2:Pattern,data=apples)
summary(apples.LSDW1)
summary(apples.LSDW2)
TukeyHSD(apples.LSDW1, which="Display")
#Yields of Amoebae
yields=read.table("https://raw.githubusercontent.com/athienit/STA4211material/main/entozamoeba.txt",header=FALSE)
colnames(yields)=c("Condition","Yields")
yields$Condition=factor(yields$Condition)
library(plyr)
ddply(yields,.(Condition),summarise,means=mean(Yields),sds=sd(Yields))
library(ggdist)
library(ggplot2)
library(gghalves)
ggplot(yields, aes(x = Condition, y = Yields,fill=Condition)) +
ggdist::stat_halfeye(
adjust = .9, #custom bandwidth
width = .6,
.width = 0,
justification = -.3,
point_colour = NA) +
geom_boxplot(
width = .25,
outlier.shape = NA
) +
geom_point(
size = 1.3,
alpha = .3,
position = position_jitter(
seed = 1, width = .1
)
) +
stat_summary(
fun = mean,
geom = "point",
shape = 17,  # Use a triangle as the point shape
size = 3,
color = "red",  # Set the color to red
position = position_dodge(width = 0.75)  # Adjust the dodge width as needed
) +
coord_cartesian(xlim = c(1.2, NA), clip = "off")
ggplot(yields, aes(x = Condition, y = Yields,fill=Condition)) +
ggdist::stat_halfeye(
adjust = .9, #custom bandwidth
width = .6,
.width = 0,
justification = -.3,
point_colour = NA) +
geom_boxplot(
width = .25,
outlier.shape = NA
) +
geom_point(
size = 1.3,
alpha = .3,
position = position_jitter(
seed = 1, width = .1
)
) +
stat_summary(
fun = mean,
geom = "point",
shape = 17,  # Use a triangle as the point shape
size = 3,
color = "red",  # Set the color to red
alpha=0.07, #opacity
position = position_dodge(width = 0.75)  # Adjust the dodge width as needed
) +
coord_cartesian(xlim = c(1.2, NA), clip = "off")
ggplot(yields, aes(x = Condition, y = Yields,fill=Condition)) +
ggdist::stat_halfeye(
adjust = .9, #custom bandwidth
width = .6,
.width = 0,
justification = -.3,
point_colour = NA) +
geom_boxplot(
width = .25,
outlier.shape = NA
) +
geom_point(
size = 1.3,
alpha = .3,
position = position_jitter(
seed = 1, width = .1
)
) +
stat_summary(
fun = mean,
geom = "point",
shape = 17,  # Use a triangle as the point shape
size = 3,
color = "red",  # Set the color to red
alpha=0.7, #opacity
position = position_dodge(width = 0.75)  # Adjust the dodge width as needed
) +
coord_cartesian(xlim = c(1.2, NA), clip = "off")
### Some cross-validation
# Load necessary libraries
library(dplyr) # For data manipulation
ddply(yields,.(Condition),summarise,means=mean(Yields),sds=sd(Yields))
library(caret) # For cross-validation
install.packages("caret")
help(createFolds)
# Define the number of folds
train_control <- trainControl(method = "cv",
number = 10)
library(MASS)  # For the Boston dataset
library(dplyr) # For data manipulation
library(caret) # For cross-validation
# Load your dataset (replace 'Boston' with your dataset)
data(Boston)
df <- Boston
# Set the seed for reproducibility
set.seed(123)
# Define the number of folds
num_folds <- 10
# Create indices for stratified 10-fold cross-validation
folds <- createFolds(df$medv, k = num_folds, list = TRUE, returnTrain = FALSE)
folds
### Some cross-validation
# Load necessary libraries
library(dplyr) # For data manipulation
library(caret) # For cross-validation
# Define the number of folds
num_folds <- 10
# Create indices for stratified 10-fold cross-validation
folds <- createFolds(df$medv, k = num_folds, list = TRUE, returnTrain = FALSE)
folds
dim(folds)
dim(folds$Fold10)
length(folds$Fold10)
df
View(df)
# Create indices for stratified 10-fold cross-validation
folds <- createFolds(yields$Yields, k = num_folds, list = TRUE, returnTrain = FALSE)
folds
help(createFolds)
# Create indices for stratified 10-fold cross-validation
folds <- createFolds(yields$Yields, k =10, p=0.7, list = TRUE, returnTrain = FALSE)
# Create indices for stratified 10-fold cross-validation
folds <- createDataPartition(yields$Yields, times =10, p=0.7, list = TRUE)
folds
# Create indices for stratified 10-fold cross-validation
folds <- createDataPartition(yields$Yields, times =1, p=0.7, list = TRUE)
folds
num_folds=10
# Create indices for stratified 10-fold cross-validation
folds <- createDataPartition(yields$Yields, times =num_folds, p=0.7, list = TRUE)
# Initialize a vector to store cross-validation results
cv_results <- numeric(num_folds)
# Perform 10-fold cross-validation
for (i in 1:num_folds) {
# Split the data into training and validation sets
train_data <- df[partitions != i, ]
valid_data <- df[partitions == i, ]
# Fit the model on the training data using aov
model <- aov(medv ~., data = train_data)
# Make predictions on the validation set
predictions <- predict(model, newdata = valid_data)
# Calculate the mean squared error (you may choose a different metric)
mse <- mean((valid_data$medv - predictions)^2)
# Store the result
cv_results[i] <- mse
}
# Create indices for stratified 10-fold cross-validation
partitions <- createDataPartition(yields$Yields, times =num_folds, p=0.7, list = TRUE)
# Initialize a vector to store cross-validation results
cv_results <- numeric(num_folds)
# Perform 10-fold cross-validation
for (i in 1:num_folds) {
# Split the data into training and validation sets
train_data <- df[partitions != i, ]
valid_data <- df[partitions == i, ]
# Fit the model on the training data using aov
model <- aov(medv ~., data = train_data)
# Make predictions on the validation set
predictions <- predict(model, newdata = valid_data)
# Calculate the mean squared error (you may choose a different metric)
mse <- mean((valid_data$medv - predictions)^2)
# Store the result
cv_results[i] <- mse
}
# Create indices for stratified 10-fold cross-validation
partitions <- createDataPartition(yields$Yields, times=1, p=0.7, list = TRUE)
# Initialize a vector to store cross-validation results
cv_results <- numeric(num_folds)
# Perform 10-fold cross-validation
for (i in 1:num_folds) {
# Split the data into training and validation sets
train_data <- df[partitions != i, ]
valid_data <- df[partitions == i, ]
# Fit the model on the training data using aov
model <- aov(medv ~., data = train_data)
# Make predictions on the validation set
predictions <- predict(model, newdata = valid_data)
# Calculate the mean squared error (you may choose a different metric)
mse <- mean((valid_data$medv - predictions)^2)
# Store the result
cv_results[i] <- mse
}
num_folds=10
# Create indices for stratified 10-fold cross-validation
partitions <- createDataPartition(yields$Yields, times=1, p=0.7, list = TRUE)
# Initialize a vector to store cross-validation results
cv_results <- numeric(num_folds)
# Perform 10-fold cross-validation
for (i in 1:num_folds) {
# Split the data into training and validation sets
train_data <- df[partitions != i, ]
valid_data <- df[partitions == i, ]
# Fit the model on the training data using aov
model <- aov(medv ~., data = train_data)
# Make predictions on the validation set
predictions <- predict(model, newdata = valid_data)
# Calculate the mean squared error (you may choose a different metric)
mse <- mean((valid_data$medv - predictions)^2)
# Store the result
cv_results[i] <- mse
}
# Calculate the mean and standard deviation of the cross-validation results
mean_mse <- mean(cv_results)
# Load necessary libraries
library(MASS)  # For the Boston dataset
library(dplyr) # For data manipulation
library(caret) # For cross-validation
# Load your dataset (replace 'Boston' with your dataset)
data(Boston)
df <- Boston
# Set the seed for reproducibility
set.seed(123)
# Define the number of folds
num_folds <- 10
# Create data partitions for stratified 10-fold cross-validation
partitions <- createDataPartition(df$medv, p = 0.9, list = FALSE)
# Initialize a vector to store cross-validation results
cv_results <- numeric(num_folds)
# Perform 10-fold cross-validation
for (i in 1:num_folds) {
# Split the data into training and validation sets
train_data <- df[partitions != i, ]
valid_data <- df[partitions == i, ]
# Fit the model on the training data using aov
model <- aov(medv ~., data = train_data)
# Make predictions on the validation set
predictions <- predict(model, newdata = valid_data)
# Calculate the mean squared error (you may choose a different metric)
mse <- mean((valid_data$medv - predictions)^2)
# Store the result
cv_results[i] <- mse
}
# Calculate the mean and standard deviation of the cross-validation results
mean_mse <- mean(cv_results)
std_mse <- sd(cv_results)
# Print the results
cat("Mean MSE:", mean_mse, "\n")
cat("Standard Deviation of MSE:", std_mse, "\n")
num_folds=10
# Create indices for stratified 10-fold cross-validation
partitions <- createDataPartition(yields$Yields, times=num_folds, p=0.7, list = TRUE)
# Initialize a vector to store cross-validation results
cv_results <- numeric(num_folds)
i=1
# Split the data into training and validation sets
train_data <- df[partitions != i, ]
num_folds=1
# Create indices for stratified 10-fold cross-validation
partitions <- createDataPartition(yields$Yields, times=num_folds, p=0.7, list = TRUE)
# Initialize a vector to store cross-validation results
cv_results <- numeric(num_folds)
# Split the data into training and validation sets
train_data <- df[partitions != i, ]
partitions
### Some cross-validation
# Load necessary libraries
library(dplyr) # For data manipulation
library(caret) # For cross-validation
# Define the number of folds
num_folds <- 10
# Create indices for stratified 10-fold cross-validation
folds <- createFolds(df$medv, k = num_folds, list = TRUE, returnTrain = FALSE)
# Initialize a vector to store cross-validation results
cv_results <- numeric(num_folds)
# Perform 10-fold cross-validation
for (i in 1:num_folds) {
# Split the data into training and validation sets
train_data <- df[-folds[[i]], ]
valid_data <- df[folds[[i]], ]
# Fit the model on the training data using aov
model <- aov(Yields ~Condition, data = train_data)
# Make predictions on the validation set
predictions <- predict(model, newdata = valid_data)
# Calculate the mean squared error (you may choose a different metric)
mse <- mean((valid_data$Yields - predictions)^2)
# Store the result
cv_results[i] <- mse
}
# Perform 10-fold cross-validation
for (i in 1:num_folds) {
# Split the data into training and validation sets
train_data <- yields[-folds[[i]], ]
valid_data <- yields[folds[[i]], ]
# Fit the model on the training data using aov
model <- aov(Yields ~Condition, data = train_data)
# Make predictions on the validation set
predictions <- predict(model, newdata = valid_data)
# Calculate the mean squared error (you may choose a different metric)
mse <- mean((valid_data$Yields - predictions)^2)
# Store the result
cv_results[i] <- mse
}
# Calculate the mean and standard deviation of the cross-validation results
mean_mse <- mean(cv_results)
std_mse <- sd(cv_results)
# Print the results
cat("Mean MSE:", mean_mse, "\n")
cat("Standard Deviation of MSE:", std_mse, "\n")
cv_results
i=1
# Split the data into training and validation sets
train_data <- yields[-folds[[i]], ]
train_data
folds[[i]]
folds
# Create indices for stratified 10-fold cross-validation
folds <- createFolds(yields$Yields, k = num_folds, list = TRUE, returnTrain = FALSE)
# Initialize a vector to store cross-validation results
cv_results <- numeric(num_folds)
# Perform 10-fold cross-validation
for (i in 1:num_folds) {
# Split the data into training and validation sets
train_data <- yields[-folds[[i]], ]
valid_data <- yields[folds[[i]], ]
# Fit the model on the training data using aov
model <- aov(Yields ~Condition, data = train_data)
# Make predictions on the validation set
predictions <- predict(model, newdata = valid_data)
# Calculate the mean squared error (you may choose a different metric)
mse <- mean((valid_data$Yields - predictions)^2)
# Store the result
cv_results[i] <- mse
}
# Calculate the mean and standard deviation of the cross-validation results
mean_mse <- mean(cv_results)
std_mse <- sd(cv_results)
# Print the results
cat("Mean MSE:", mean_mse, "\n")
cat("Standard Deviation of MSE:", std_mse, "\n")
cv_results
# Create indices for stratified 10-fold cross-validation
folds <- createFolds(yields$Yields, k = num_folds, list = TRUE, returnTrain = FALSE)
folds
# Create indices for stratified 10-fold cross-validation
folds <- createDataPartition(yields$Yields, k = num_folds, p=0.8, list = TRUE, returnTrain = FALSE)
# Create indices for stratified 10-fold cross-validation
folds <- createDataPartition(yields$Yields, times = num_folds, p=0.8, list = TRUE, returnTrain = FALSE)
# Create indices for stratified 10-fold cross-validation
folds <- createDataPartition(yields$Yields, times = num_folds, p=0.8, list = TRUE)
folds
# Initialize a vector to store cross-validation results
cv_results <- numeric(num_folds)
# Perform 10-fold cross-validation
for (i in 1:num_folds) {
# Split the data into training and validation sets
train_data <- yields[-folds[[i]], ]
valid_data <- yields[folds[[i]], ]
# Fit the model on the training data using aov
model <- aov(Yields ~Condition, data = train_data)
# Make predictions on the validation set
predictions <- predict(model, newdata = valid_data)
# Calculate the mean squared error (you may choose a different metric)
mse <- mean((valid_data$Yields - predictions)^2)
# Store the result
cv_results[i] <- mse
}
i
# Split the data into training and validation sets
train_data <- yields[-folds[[i]], ]
valid_data <- yields[folds[[i]], ]
train_data
# Create indices for stratified 10-fold cross-validation
folds <- createDataPartition(yields$Yields, times = num_folds, p=0.8, list = TRUE)
folds
i=1
# Split the data into training and validation sets
train_data <- yields[-folds[[i]], ]
valid_data <- yields[folds[[i]], ]
# Fit the model on the training data using aov
model <- aov(Yields ~Condition, data = train_data)
summary(model)
0.8*50
# Create indices for stratified 10-fold cross-validation
folds <- createDataPartition(yields$Yields, times = num_folds, p=0.2, list = TRUE)
# Initialize a vector to store cross-validation results
cv_results <- numeric(num_folds)
# Split the data into training and validation sets
train_data <- yields[-folds[[i]], ]
valid_data <- yields[folds[[i]], ]
train_data
valid_data <- yields[folds[[i]], ]
# Fit the model on the training data using aov
model <- aov(Yields ~Condition, data = train_data)
# Calculate the mean squared error (you may choose a different metric)
mse <- mean((valid_data$Yields - predictions)^2)
# Store the result
cv_results[i] <- mse
cv_results
i=2
# Split the data into training and validation sets
train_data <- yields[-folds[[i]], ]
valid_data <- yields[folds[[i]], ]
# Fit the model on the training data using aov
model <- aov(Yields ~Condition, data = train_data)
# Perform 10-fold cross-validation
for (i in 1:num_folds) {
# Split the data into training and validation sets
train_data <- yields[-folds[[i]], ]
valid_data <- yields[folds[[i]], ]
# Fit the model on the training data using aov
model <- aov(Yields ~Condition, data = train_data)
# Make predictions on the validation set
predictions <- predict(model, newdata = valid_data)
# Calculate the mean squared error (you may choose a different metric)
mse <- mean((valid_data$Yields - predictions)^2)
# Store the result
cv_results[i] <- mse
}
cv_results
# Calculate the mean and standard deviation of the cross-validation results
mean_mse <- mean(cv_results)
std_mse <- sd(cv_results)
# Print the results
cat("Mean MSE:", mean_mse, "\n")
cat("Standard Deviation of MSE:", std_mse, "\n")
